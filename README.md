# Hybrid Cloud Data Pipeline: LocalStack to GCP

This project implements a seamless cross-cloud data pipeline that integrates local AWS services (via LocalStack) with Google Cloud Platform (GCP). It demonstrates a **"dual-write" architecture** where data ingested locally is processed in the cloud and synchronized back to a local database.

---

## ðŸ— Architecture Overview

The pipeline follows a sophisticated event-driven flow:

1. **Ingestion** â€” A JSON file is uploaded to an S3 Bucket in LocalStack.
2. **Notification** â€” S3 triggers an event notification to an SQS Queue.
3. **The Bridge** â€” A custom Python Bridge application (Dockerized) polls SQS, fetches the file from S3, and publishes the content to a GCP Pub/Sub Topic.
4. **Processing** â€” A GCP Cloud Function (triggered by Pub/Sub) processes the data.
5. **Dual-Write Persistence**
   - The function writes the record to a **GCP Cloud SQL (PostgreSQL)** instance.
   - The function reaches back to the local environment via an **Ngrok Tunnel** to write the record into a **LocalStack DynamoDB** table.

---

## ðŸ›  Prerequisites

- Docker & Docker Compose
- Terraform (v1.0+)
- Google Cloud SDK (`gcloud`)
- Ngrok (for local tunneling)
- AWS CLI & `awslocal` (for manual verification)

---

## ðŸš€ Getting Started

### 1. Clone the Repository
```bash 
git clone https://github.com/Ravindra-Reddy27/multi-cloud-pipeline.git
cd multi-cloud-pipeline
```

### 2. Setup Local Tunneling

Since GCP Cloud Functions cannot natively "see" your localhost, start an Ngrok tunnel to expose LocalStack:

```bash
ngrok http 4566
```

Copy the **Forwarding URL** (e.g., `https://your-id.ngrok-free.dev`)and never close that terminal (Close terminal âŒ â†’ URL stops working immediately). You will need this for Terraform.

---

### 3. Create Your `.env` File

create a file named `.env` in the root directory. You can use the provided `.env.example` as a template. This file tells the Bridge App and Docker how to connect to your specific cloud resources.


#### `.env.example` Content

```bash
# GCP Configuration
GCP_PROJECT_ID      = "your-real-project-id"
GCP_REGION          = "your-region"
PATH_TO_GCP_KEYFILE = "gcp-key.json file path"  # Point this to your downloaded JSON key

# LocalStack/AWS Configuration (Standard for LocalStack)
AWS_ACCESS_KEY_ID       =test
AWS_SECRET_ACCESS_KEY   =test
AWS_DEFAULT_REGION      =us-east-1
```


---

### 4. Configure Environment

**a.** Place your GCP Service Account Key (JSON) in the project root.

**b.** Create a `terraform/terraform.tfvars` file:

```hcl
gcp_project_id          = "your-project-id"
gcp_region              = "your-region"  # deafault is us-central1
gcp_keyfile_path        = "gcp-key.json file-path"
db_user                 = "your-db-user" # default is postgres
db_pass                 = "your-secure-password"
db_name                 = "your-db-name" # default is pipelinedb
localstack_dynamodb_url = "https://your-id.ngrok-free.dev"
```

---

### 5. Launch the Environment

From the root directory, build and start the services:

```bash
docker-compose up --build -d
```

> **Note:** 
> 1. This starts LocalStack and the Bridge Application. Data is persisted in `./localstack_data`.

>2. If you run `docker-compose up` for all services at once, the `bridge` container may fail because the SQS queue is not yet created by Terraform.

---

### 6. Provision Infrastructure

Navigate to the terraform directory and deploy:

```bash
cd terraform
terraform init
terraform apply -auto-approve
```
---

### 7. Start the Bridge Application

Now that the SQS queue and Pub/Sub topics exist, start the Bridge container:

```bash
cd ..
docker-compose up -d bridge
```


> âš ï¸ **Important Note**
>
> If you run `docker-compose up` for all services at once, the `bridge` container may fail because the SQS queue is not yet created by Terraform. If this happens, simply run the command below after your `terraform apply` is finished:
>
> ```bash
> docker-compose restart bridge
> ```

---

## ðŸ§ª Verification Steps

### Trigger the Pipeline

Upload the test event to S3:

```bash
aws --endpoint-url=http://localhost:4566 s3 cp test-event.json s3://hybrid-cloud-bucket/
```
---

### Check GCP Cloud SQL

Verify the data reached the cloud:

```bash
gcloud sql connect hybrid-pipeline-sql-instance --user=<your-db_user>
# Run: SELECT * FROM records WHERE id = 'xyz-789';
```
### Verify Data via GCP Console UI


#### Step 1 â€” Navigate to Cloud SQL

- Open the [Google Cloud Console](https://console.cloud.google.com).
- In the search bar at the top, type **"SQL"** and select it from the results.



#### Step 2 â€” Select Your Instance

- Click on the ID of your instance:
  ```
  hybrid-pipeline-sql-instance-xxxx
  ```
  > **Note:** The name will have a random suffix generated by Terraform.


#### Step 3 â€” Open the Query Tool

- In the left-hand navigation menu, under the **"Primary Instance"** section, click on **"Cloud SQL Studio"** *(or "Query Editor" depending on your region's UI version)*.


#### Step 4 â€” Authenticate

Fill in the credentials as follows:

| Field | Value |
|---|---| 
| **Database** | `pipelinedb` *(or the user defined in your variables)* |
| **User** | `postgres` *(or the user defined in your variables)* |
| **Password** | The password you set in `terraform.tfvars` |


#### Step 5 â€” Run the Query

In the query editor window, paste the following SQL and click the **"Run"** button:

```sql
SELECT * FROM records WHERE id = 'xyz-789';
```


#### Step 6 â€” Verify Results

The results table at the bottom should display a row containing:

- `recordId` â†’ `xyz-789`
- Your test email address
- The value `120`

---
### Check Local DynamoDB

Verify the "write-back" was successful:

```bash
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name processed-records
```
---

## ðŸ’¡ Technical Notes

| Topic | Detail |
|---|---|
| **Persistence** | LocalStack data is mounted to `/var/lib/localstack` to ensure stability across container restarts. |
| **Networking** | The Bridge app uses the internal Docker network to communicate with LocalStack at `http://localstack:4566`. |
| **Security** | Cloud SQL is configured with authorized networks to allow Cloud Function access, and sensitive variables are managed via Terraform. |
